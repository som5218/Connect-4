{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento de los 2 agentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partida 1000/100000 completada.\n",
      "Partida 2000/100000 completada.\n",
      "Partida 3000/100000 completada.\n",
      "Partida 4000/100000 completada.\n",
      "Partida 5000/100000 completada.\n",
      "Partida 6000/100000 completada.\n",
      "Partida 7000/100000 completada.\n",
      "Partida 8000/100000 completada.\n",
      "Partida 9000/100000 completada.\n",
      "Partida 10000/100000 completada.\n",
      "Partida 11000/100000 completada.\n",
      "Partida 12000/100000 completada.\n",
      "Partida 13000/100000 completada.\n",
      "Partida 14000/100000 completada.\n",
      "Partida 15000/100000 completada.\n",
      "Partida 16000/100000 completada.\n",
      "Partida 17000/100000 completada.\n",
      "Partida 18000/100000 completada.\n",
      "Partida 19000/100000 completada.\n",
      "Partida 20000/100000 completada.\n",
      "Partida 21000/100000 completada.\n",
      "Partida 22000/100000 completada.\n",
      "Partida 23000/100000 completada.\n",
      "Partida 24000/100000 completada.\n",
      "Partida 25000/100000 completada.\n",
      "Partida 26000/100000 completada.\n",
      "Partida 27000/100000 completada.\n",
      "Partida 28000/100000 completada.\n",
      "Partida 29000/100000 completada.\n",
      "Partida 30000/100000 completada.\n",
      "Partida 31000/100000 completada.\n",
      "Partida 32000/100000 completada.\n",
      "Partida 33000/100000 completada.\n",
      "Partida 34000/100000 completada.\n",
      "Partida 35000/100000 completada.\n",
      "Partida 36000/100000 completada.\n",
      "Partida 37000/100000 completada.\n",
      "Partida 38000/100000 completada.\n",
      "Partida 39000/100000 completada.\n",
      "Partida 40000/100000 completada.\n",
      "Partida 41000/100000 completada.\n",
      "Partida 42000/100000 completada.\n",
      "Partida 43000/100000 completada.\n",
      "Partida 44000/100000 completada.\n",
      "Partida 45000/100000 completada.\n",
      "Partida 46000/100000 completada.\n",
      "Partida 47000/100000 completada.\n",
      "Partida 48000/100000 completada.\n",
      "Partida 49000/100000 completada.\n",
      "Partida 50000/100000 completada.\n",
      "Partida 51000/100000 completada.\n",
      "Partida 52000/100000 completada.\n",
      "Partida 53000/100000 completada.\n",
      "Partida 54000/100000 completada.\n",
      "Partida 55000/100000 completada.\n",
      "Partida 56000/100000 completada.\n",
      "Partida 57000/100000 completada.\n",
      "Partida 58000/100000 completada.\n",
      "Partida 59000/100000 completada.\n",
      "Partida 60000/100000 completada.\n",
      "Partida 61000/100000 completada.\n",
      "Partida 62000/100000 completada.\n",
      "Partida 63000/100000 completada.\n",
      "Partida 64000/100000 completada.\n",
      "Partida 65000/100000 completada.\n",
      "Partida 66000/100000 completada.\n",
      "Partida 67000/100000 completada.\n",
      "Partida 68000/100000 completada.\n",
      "Partida 69000/100000 completada.\n",
      "Partida 70000/100000 completada.\n",
      "Partida 71000/100000 completada.\n",
      "Partida 72000/100000 completada.\n",
      "Partida 73000/100000 completada.\n",
      "Partida 74000/100000 completada.\n",
      "Partida 75000/100000 completada.\n",
      "Partida 76000/100000 completada.\n",
      "Partida 77000/100000 completada.\n",
      "Partida 78000/100000 completada.\n",
      "Partida 79000/100000 completada.\n",
      "Partida 80000/100000 completada.\n",
      "Partida 81000/100000 completada.\n",
      "Partida 82000/100000 completada.\n",
      "Partida 83000/100000 completada.\n",
      "Partida 84000/100000 completada.\n",
      "Partida 85000/100000 completada.\n",
      "Partida 86000/100000 completada.\n",
      "Partida 87000/100000 completada.\n",
      "Partida 88000/100000 completada.\n",
      "Partida 89000/100000 completada.\n",
      "Partida 90000/100000 completada.\n",
      "Partida 91000/100000 completada.\n",
      "Partida 92000/100000 completada.\n",
      "Partida 93000/100000 completada.\n",
      "Partida 94000/100000 completada.\n",
      "Partida 95000/100000 completada.\n",
      "Partida 96000/100000 completada.\n",
      "Partida 97000/100000 completada.\n",
      "Partida 98000/100000 completada.\n",
      "Partida 99000/100000 completada.\n",
      "Partida 100000/100000 completada.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Clase que define el entorno del juego, es decir, el tablero de Connect 4\n",
    "class Ambiente:\n",
    "    def __init__(self):\n",
    "        # Define el tamaño del tablero (6 filas x 7 columnas)\n",
    "        self.rows = 6\n",
    "        self.columns = 7\n",
    "        self.reset()  # Inicializa el tablero\n",
    "\n",
    "    def reset(self):\n",
    "        # Resetea el tablero y establece los valores iniciales\n",
    "        self.board = np.zeros((self.rows, self.columns))\n",
    "        self.turn = 1  # Jugador inicial (1: Rojo, -1: Amarillo)\n",
    "        self.moves_made = 0  # Contador de movimientos\n",
    "        self.done = False  # Indica si el juego ha terminado\n",
    "\n",
    "    def is_valid_move(self, column):\n",
    "        # Verifica si se puede hacer un movimiento en la columna (si la columna no está llena)\n",
    "        return self.board[0][column] == 0\n",
    "\n",
    "    def get_valid_moves(self):\n",
    "        # Retorna una lista de columnas válidas (donde aún se puede jugar)\n",
    "        return [col for col in range(self.columns) if self.is_valid_move(col)]\n",
    "\n",
    "    def play_move(self, column):\n",
    "        # Intenta jugar en la columna especificada, y retorna False si la columna está llena\n",
    "        if not self.is_valid_move(column):\n",
    "            return False\n",
    "        # Coloca la ficha en la posición más baja disponible de la columna\n",
    "        for row in range(self.rows - 1, -1, -1):\n",
    "            if self.board[row][column] == 0:\n",
    "                self.board[row][column] = self.turn  # Coloca la ficha\n",
    "                self.moves_made += 1  # Incrementa el contador de movimientos\n",
    "                break\n",
    "        return True\n",
    "\n",
    "    def switch_turn(self):\n",
    "        # Cambia el turno del jugador (entre 1 y -1)\n",
    "        self.turn *= -1\n",
    "\n",
    "    def check_winner(self):\n",
    "        # Revisa todas las posibles combinaciones de 4 en línea para determinar si hay un ganador\n",
    "        for c in range(self.columns - 3):\n",
    "            for r in range(self.rows):\n",
    "                # Horizontal\n",
    "                if np.abs(np.sum(self.board[r, c:c + 4])) == 4:\n",
    "                    return True\n",
    "        for c in range(self.columns):\n",
    "            for r in range(self.rows - 3):\n",
    "                # Vertical\n",
    "                if np.abs(np.sum(self.board[r:r + 4, c])) == 4:\n",
    "                    return True\n",
    "        for c in range(self.columns - 3):\n",
    "            for r in range(self.rows - 3):\n",
    "                # Diagonal descendente\n",
    "                if np.abs(np.sum([self.board[r + i, c + i] for i in range(4)])) == 4:\n",
    "                    return True\n",
    "                # Diagonal ascendente\n",
    "                if np.abs(np.sum([self.board[r + 3 - i, c + i] for i in range(4)])) == 4:\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    def is_draw(self):\n",
    "        # Verifica si el tablero está lleno, lo que indica un empate\n",
    "        return self.moves_made == self.rows * self.columns\n",
    "\n",
    "# Clase que define el agente que juega Connect 4 usando Q-learning\n",
    "class Agente:\n",
    "    def __init__(self, gamma=0.95, lr=0.01):\n",
    "        self.q_table = {}  # Inicializa la tabla Q\n",
    "        self.gamma = gamma  # Factor de descuento para valores futuros\n",
    "        self.lr = lr  # Tasa de aprendizaje\n",
    "        self.epsilon = 1.0  # Valor inicial de epsilon para exploración\n",
    "        self.epsilon_decay = 0.999  # Decaimiento de epsilon\n",
    "        self.epsilon_min = 0.05  # Valor mínimo de epsilon para mantener algo de exploración\n",
    "\n",
    "    def get_state(self, env):\n",
    "        # Convierte el tablero a una tupla para usarlo como estado en la Q-table\n",
    "        return tuple(map(tuple, env.board))\n",
    "\n",
    "    def choose_action(self, env):\n",
    "        # Selecciona una acción usando una política epsilon-greedy\n",
    "        state = self.get_state(env)\n",
    "        if state not in self.q_table:\n",
    "            # Inicializa los Q-valores para nuevos estados\n",
    "            self.q_table[state] = [0] * env.columns\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            # Explora una acción al azar\n",
    "            return random.choice(env.get_valid_moves())\n",
    "        else:\n",
    "            # Explota el mejor movimiento basado en la Q-table\n",
    "            return self.get_best_action(state, env)\n",
    "\n",
    "    def get_best_action(self, state, env):\n",
    "        # Retorna la mejor acción basada en los valores Q, penalizando las columnas inválidas\n",
    "        valid_moves = env.get_valid_moves()\n",
    "        q_values = np.array(self.q_table[state], dtype=float)\n",
    "        q_values_invalid = [i for i in range(env.columns) if i not in valid_moves]\n",
    "        q_values[q_values_invalid] = -1e6  # Asigna un valor bajo a las columnas llenas\n",
    "        return np.argmax(q_values)\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state):\n",
    "        # Actualiza el Q-valor de un estado y acción específicos\n",
    "        if next_state not in self.q_table:\n",
    "            self.q_table[next_state] = [0] * env.columns\n",
    "        max_future_q = max(self.q_table[next_state])  # Máximo Q del siguiente estado\n",
    "        current_q = self.q_table[state][action]\n",
    "        # Fórmula de actualización de Q-Learning\n",
    "        self.q_table[state][action] = current_q + self.lr * (reward + self.gamma * max_future_q - current_q)\n",
    "\n",
    "    def save_q_table(self, file_name):\n",
    "        # Guarda la Q-table en un archivo para cargarla más tarde\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(self.q_table, f)\n",
    "\n",
    "# Función para jugar una partida entre dos agentes\n",
    "def jugar_partida(agente_rojo, agente_amarillo, env):\n",
    "    env.reset()\n",
    "    agentes = [agente_rojo, agente_amarillo]  # Lista de agentes, rojo y amarillo\n",
    "    turno = 0  # Inicia con el agente rojo\n",
    "    state_action_history = []  # Guarda el historial de estados y acciones\n",
    "\n",
    "    while not env.done:\n",
    "        agente_actual = agentes[turno]\n",
    "        state = agente_actual.get_state(env)\n",
    "        action = agente_actual.choose_action(env)\n",
    "        state_action_history.append((state, action, turno))  # Guarda la acción tomada\n",
    "\n",
    "        env.play_move(action)\n",
    "        next_state = agente_actual.get_state(env)\n",
    "\n",
    "        if env.check_winner():\n",
    "            # Actualizar Q-valores para ambos agentes si hay un ganador\n",
    "            for s, a, t in reversed(state_action_history):\n",
    "                reward = 1 if t == turno else -1  # Recompensa para el ganador, castigo para el perdedor\n",
    "                agentes[t].update_q_value(s, a, reward, next_state)\n",
    "            env.done = True\n",
    "            return 1 if turno == 0 else -1\n",
    "        elif env.is_draw():\n",
    "            # Actualizar Q-valores para ambos agentes en caso de empate\n",
    "            for s, a, t in reversed(state_action_history):\n",
    "                agentes[t].update_q_value(s, a, 0, next_state)  # Recompensa neutra en caso de empate\n",
    "            env.done = True\n",
    "            return 0\n",
    "        else:\n",
    "            # Actualizar Q-valores sin recompensa\n",
    "            agentes[turno].update_q_value(state, action, 0, next_state)\n",
    "\n",
    "        env.switch_turn()  # Cambiar el turno al otro agente\n",
    "        turno = 1 - turno  # Alternar entre 0 y 1\n",
    "\n",
    "# Código principal para entrenar a los agentes y guardar sus Q-tables\n",
    "if __name__ == \"__main__\":\n",
    "    env = Ambiente()  # Inicializa el entorno\n",
    "    agente_rojo = Agente()  # Crea el agente rojo\n",
    "    agente_amarillo = Agente()  # Crea el agente amarillo\n",
    "\n",
    "    partidas = 100000  # Número de partidas para entrenar\n",
    "    resultados = []  # Almacena los resultados de cada partida\n",
    "\n",
    "    for i in range(partidas):\n",
    "        resultado = jugar_partida(agente_rojo, agente_amarillo, env)\n",
    "        resultados.append(resultado)\n",
    "        # Reducir epsilon después de cada partida para más explotación y menos exploración\n",
    "        agente_rojo.epsilon = max(agente_rojo.epsilon * agente_rojo.epsilon_decay, agente_rojo.epsilon_min)\n",
    "        agente_amarillo.epsilon = max(agente_amarillo.epsilon * agente_amarillo.epsilon_decay, agente_amarillo.epsilon_min)\n",
    "        if (i+1) % 1000 == 0:\n",
    "            print(f\"Partida {i+1}/{partidas} completada.\")\n",
    "\n",
    "    # Guardar las Q-tables de ambos agentes en archivos\n",
    "    agente_rojo.save_q_table(\"q_table_rojo.pkl\")\n",
    "    agente_amarillo.save_q_table(\"q_table_amarillo.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resultados' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Contar y graficar resultados\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m victorias_rojo \u001b[38;5;241m=\u001b[39m resultados\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m victorias_amarillo \u001b[38;5;241m=\u001b[39m resultados\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m empates \u001b[38;5;241m=\u001b[39m resultados\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'resultados' is not defined"
     ]
    }
   ],
   "source": [
    "# Contar y graficar resultados\n",
    "victorias_rojo = resultados.count(1)\n",
    "victorias_amarillo = resultados.count(-1)\n",
    "empates = resultados.count(0)\n",
    "# Crear gráfico de barras\n",
    "labels = ['Rojo', 'Amarillo', 'Empate']\n",
    "values = [victorias_rojo, victorias_amarillo, empates]\n",
    "plt.bar(labels, values, color=['red', 'yellow', 'gray'])\n",
    "plt.title('Distribución de Resultados')\n",
    "plt.xlabel('Resultado')\n",
    "plt.ylabel('Número de Partidas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Cargar el archivo .pkl\n",
    "with open('q_table_rojo.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Mostrar el contenido del archivo\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agente_rojo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNúmero de estados en la Q-table:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(agente_rojo\u001b[38;5;241m.\u001b[39mq_table))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agente_rojo' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Número de estados en la Q-table:\", len(agente_rojo.q_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "from tkinter import messagebox\n",
    "\n",
    "# Clase que define el entorno del juego, es decir, el tablero de Connect 4\n",
    "class Ambiente:\n",
    "    def __init__(self):\n",
    "        self.rows = 6  # Número de filas del tablero\n",
    "        self.columns = 7  # Número de columnas del tablero\n",
    "        self.reset()  # Inicializa el tablero\n",
    "\n",
    "    def reset(self):\n",
    "        # Crea una matriz de ceros para representar el tablero vacío\n",
    "        self.board = np.zeros((self.rows, self.columns))\n",
    "        self.turn = 1  # Turno del jugador actual (1 para rojo, -1 para amarillo)\n",
    "        self.moves_made = 0  # Contador de movimientos realizados\n",
    "        self.done = False  # Indica si el juego ha terminado\n",
    "\n",
    "    def is_valid_move(self, column):\n",
    "        # Verifica si se puede realizar un movimiento en la columna (si no está llena)\n",
    "        return self.board[0][column] == 0\n",
    "\n",
    "    def get_valid_moves(self):\n",
    "        # Devuelve una lista de columnas donde es posible hacer un movimiento\n",
    "        return [col for col in range(self.columns) if self.is_valid_move(col)]\n",
    "\n",
    "    def play_move(self, column):\n",
    "        # Realiza un movimiento en la columna especificada\n",
    "        if not self.is_valid_move(column):\n",
    "            return False  # Movimiento inválido si la columna está llena\n",
    "        # Coloca la ficha en la posición más baja disponible en la columna\n",
    "        for row in range(self.rows - 1, -1, -1):\n",
    "            if self.board[row][column] == 0:\n",
    "                self.board[row][column] = self.turn  # Coloca la ficha del jugador actual\n",
    "                self.moves_made += 1  # Incrementa el contador de movimientos\n",
    "                break\n",
    "        return True\n",
    "\n",
    "    def switch_turn(self):\n",
    "        # Cambia el turno al otro jugador\n",
    "        self.turn *= -1\n",
    "\n",
    "    def check_winner(self):\n",
    "        # Verifica si hay un ganador en el tablero\n",
    "\n",
    "        # Comprobación horizontal\n",
    "        for c in range(self.columns - 3):\n",
    "            for r in range(self.rows):\n",
    "                if np.abs(np.sum(self.board[r, c:c + 4])) == 4:\n",
    "                    return True  # Hay un ganador\n",
    "\n",
    "        # Comprobación vertical\n",
    "        for c in range(self.columns):\n",
    "            for r in range(self.rows - 3):\n",
    "                if np.abs(np.sum(self.board[r:r + 4, c])) == 4:\n",
    "                    return True  # Hay un ganador\n",
    "\n",
    "        # Comprobación de diagonales\n",
    "        for c in range(self.columns - 3):\n",
    "            for r in range(self.rows - 3):\n",
    "                # Diagonal descendente (\\)\n",
    "                if np.abs(np.sum([self.board[r + i, c + i] for i in range(4)])) == 4:\n",
    "                    return True  # Hay un ganador\n",
    "                # Diagonal ascendente (/)\n",
    "                if np.abs(np.sum([self.board[r + 3 - i, c + i] for i in range(4)])) == 4:\n",
    "                    return True  # Hay un ganador\n",
    "\n",
    "        return False  # No hay ganador\n",
    "\n",
    "    def is_draw(self):\n",
    "        # Verifica si el juego es un empate (tablero lleno)\n",
    "        return self.moves_made == self.rows * self.columns\n",
    "\n",
    "# Clase que define el agente que juega usando una tabla Q\n",
    "class Agente:\n",
    "    def __init__(self, gamma=0.95, lr=0.01):\n",
    "        self.q_table = {}  # Tabla Q para almacenar los valores Q\n",
    "        self.gamma = gamma  # Factor de descuento\n",
    "        self.lr = lr  # Tasa de aprendizaje\n",
    "        self.epsilon = 0.05  # Pequeño valor para permitir algo de exploración\n",
    "\n",
    "    def load_q_table(self, file_name):\n",
    "        # Carga la tabla Q desde un archivo\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.q_table = pickle.load(f)\n",
    "\n",
    "    def get_state(self, env):\n",
    "        # Convierte el tablero en una representación inmutable (tupla) para usar como clave en la tabla Q\n",
    "        return tuple(map(tuple, env.board))\n",
    "\n",
    "    def choose_action(self, env):\n",
    "        # Elige una acción usando una política ε-greedy\n",
    "        state = self.get_state(env)\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            # Explorar: elegir una acción válida al azar\n",
    "            return random.choice(env.get_valid_moves())\n",
    "        elif state in self.q_table:\n",
    "            # Explotar: elegir la mejor acción conocida según la tabla Q\n",
    "            return self.get_best_action(state, env)\n",
    "        else:\n",
    "            # Estado desconocido: seleccionar acción válida al azar\n",
    "            return random.choice(env.get_valid_moves())\n",
    "\n",
    "    def get_best_action(self, state, env):\n",
    "        # Obtiene la mejor acción para un estado dado basado en la tabla Q\n",
    "        valid_moves = env.get_valid_moves()\n",
    "        q_values = np.array(self.q_table[state], dtype=float)\n",
    "        # Penaliza las acciones inválidas asignándoles un valor muy bajo\n",
    "        q_values[~np.isin(range(env.columns), valid_moves)] = -1e6\n",
    "        return np.argmax(q_values)  # Retorna el índice de la acción con el valor Q más alto\n",
    "\n",
    "# Clase que maneja la interfaz gráfica del juego\n",
    "class Connect4GUI:\n",
    "    def __init__(self, env, agente_rojo=None):\n",
    "        self.env = env  # Entorno del juego\n",
    "        self.agente_rojo = agente_rojo  # Agente que juega con fichas rojas\n",
    "        self.window = tk.Tk()  # Ventana principal de Tkinter\n",
    "        self.window.title(\"Conecta 4 - Humano (Amarillo) vs. Agente (Rojo)\")\n",
    "\n",
    "        # Botones de columna para que el jugador humano seleccione dónde colocar su ficha\n",
    "        self.buttons = [\n",
    "            tk.Button(\n",
    "                self.window,\n",
    "                text=\"▼\",\n",
    "                font=(\"Arial\", 16, \"bold\"),\n",
    "                bg=\"gold\",\n",
    "                command=lambda c=i: self.human_move(c)\n",
    "            )\n",
    "            for i in range(self.env.columns)\n",
    "        ]\n",
    "        # Colocar los botones en la ventana\n",
    "        for i, button in enumerate(self.buttons):\n",
    "            button.grid(row=0, column=i, sticky=\"nsew\", padx=2, pady=2)\n",
    "\n",
    "        # Canvas para dibujar el tablero del juego\n",
    "        self.canvas = tk.Canvas(\n",
    "            self.window,\n",
    "            width=self.env.columns * 100,\n",
    "            height=self.env.rows * 100,\n",
    "            bg=\"#1E90FF\"\n",
    "        )\n",
    "        self.canvas.grid(row=1, column=0, columnspan=self.env.columns, padx=5, pady=5)\n",
    "        # Crear círculos que representan las posiciones en el tablero\n",
    "        self.circles = [\n",
    "            [\n",
    "                self.canvas.create_oval(\n",
    "                    j * 100 + 10,\n",
    "                    i * 100 + 10,\n",
    "                    j * 100 + 90,\n",
    "                    i * 100 + 90,\n",
    "                    fill=\"white\"  # Color inicial de los círculos (vacíos)\n",
    "                )\n",
    "                for j in range(self.env.columns)\n",
    "            ]\n",
    "            for i in range(self.env.rows)\n",
    "        ]\n",
    "\n",
    "        # Configurar la distribución de columnas y filas en el grid\n",
    "        for i in range(self.env.columns):\n",
    "            self.window.grid_columnconfigure(i, weight=1)\n",
    "        self.window.grid_rowconfigure(1, weight=1)\n",
    "        self.turn = \"yellow\"  # Comienza el jugador humano (amarillo)\n",
    "\n",
    "    def disable_buttons(self):\n",
    "        # Deshabilita los botones para que el jugador no pueda realizar movimientos fuera de turno\n",
    "        for button in self.buttons:\n",
    "            button.config(state=tk.DISABLED)\n",
    "\n",
    "    def enable_buttons(self):\n",
    "        # Habilita los botones para que el jugador pueda realizar movimientos en su turno\n",
    "        for button in self.buttons:\n",
    "            button.config(state=tk.NORMAL)\n",
    "\n",
    "    def human_move(self, column):\n",
    "        # Maneja el movimiento del jugador humano\n",
    "        if self.turn != \"yellow\":\n",
    "            return  # Si no es el turno del jugador, no hacer nada\n",
    "        if not self.env.is_valid_move(column):\n",
    "            # Mostrar un mensaje si la columna está llena\n",
    "            messagebox.showwarning(\"Columna llena\", \"Esta columna está llena. Elige otra.\")\n",
    "            return\n",
    "\n",
    "        # Realizar el movimiento del jugador humano en el entorno\n",
    "        self.env.play_move(column)\n",
    "        # Encontrar la fila donde se colocó la ficha\n",
    "        row = next(r for r in range(self.env.rows) if self.env.board[r][column] != 0)\n",
    "        # Actualizar el círculo correspondiente en la interfaz gráfica\n",
    "        self.canvas.itemconfig(self.circles[row][column], fill=\"yellow\")\n",
    "\n",
    "        if self.env.check_winner():\n",
    "            # Si el jugador humano gana, mostrar mensaje y reiniciar el juego\n",
    "            messagebox.showinfo(\"Fin del juego\", \"¡Ganaste!\")\n",
    "            self.reset_game()\n",
    "            return\n",
    "        elif self.env.is_draw():\n",
    "            # Si hay empate, mostrar mensaje y reiniciar el juego\n",
    "            messagebox.showinfo(\"Fin del juego\", \"¡Es un empate!\")\n",
    "            self.reset_game()\n",
    "            return\n",
    "\n",
    "        # Cambiar el turno al agente\n",
    "        self.env.switch_turn()\n",
    "        self.turn = \"red\"\n",
    "        self.disable_buttons()  # Deshabilitar botones mientras juega el agente\n",
    "        self.window.after(500, self.agent_play)  # Esperar medio segundo antes de que el agente juegue\n",
    "\n",
    "    def agent_play(self):\n",
    "        # Maneja el movimiento del agente\n",
    "        if self.turn != \"red\" or not self.agente_rojo:\n",
    "            return  # Si no es el turno del agente o no hay agente, no hacer nada\n",
    "\n",
    "        # El agente elige una acción basada en su política\n",
    "        action = self.agente_rojo.choose_action(self.env)\n",
    "        # Realizar el movimiento del agente en el entorno\n",
    "        self.env.play_move(action)\n",
    "        # Encontrar la fila donde se colocó la ficha\n",
    "        row = next(r for r in range(self.env.rows) if self.env.board[r][action] != 0)\n",
    "        # Actualizar el círculo correspondiente en la interfaz gráfica\n",
    "        self.canvas.itemconfig(self.circles[row][action], fill=\"red\")\n",
    "\n",
    "        if self.env.check_winner():\n",
    "            # Si el agente gana, mostrar mensaje y reiniciar el juego\n",
    "            messagebox.showinfo(\"Fin del juego\", \"¡El agente rojo ha ganado!\")\n",
    "            self.reset_game()\n",
    "            return\n",
    "        elif self.env.is_draw():\n",
    "            # Si hay empate, mostrar mensaje y reiniciar el juego\n",
    "            messagebox.showinfo(\"Fin del juego\", \"¡Es un empate!\")\n",
    "            self.reset_game()\n",
    "            return\n",
    "\n",
    "        # Cambiar el turno al jugador humano\n",
    "        self.env.switch_turn()\n",
    "        self.turn = \"yellow\"\n",
    "        self.enable_buttons()  # Habilitar botones para que el jugador pueda hacer su movimiento\n",
    "\n",
    "    def reset_game(self):\n",
    "        # Reinicia el estado del juego y actualiza la interfaz gráfica\n",
    "        self.env.reset()\n",
    "        self.turn = \"yellow\"  # Comienza el turno del jugador humano\n",
    "        for i in range(self.env.rows):\n",
    "            for j in range(self.env.columns):\n",
    "                # Restablecer el color de todos los círculos a blanco (vacío)\n",
    "                self.canvas.itemconfig(self.circles[i][j], fill=\"white\")\n",
    "        self.enable_buttons()  # Habilitar botones para el nuevo juego\n",
    "\n",
    "    def run(self):\n",
    "        # Inicia el bucle principal de la interfaz gráfica\n",
    "        self.window.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = Ambiente()  # Crear el entorno del juego\n",
    "    agente_rojo = Agente()  # Crear el agente rojo\n",
    "    agente_rojo.load_q_table(\"q_table_rojo.pkl\")  # Cargar la tabla Q entrenada del agente\n",
    "    gui = Connect4GUI(env, agente_rojo)  # Crear la interfaz gráfica con el entorno y el agente\n",
    "    gui.run()  # Ejecutar el juego\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
